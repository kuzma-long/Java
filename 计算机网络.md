## OSI 七层模型（TCP/IP四层模型）

> 百度，字节tiktok，华为，阿里云，蔚来

![OSI 七层模型](https://guide-blog-images.oss-cn-shenzhen.aliyuncs.com/github/javaguide/cs-basics/network/osi-7-model.png)

![各层网络对应的网络协议](https://cdn.tobebetterjavaer.com/tobebetterjavaer/images/nice-article/weixin-mianznxjsjwllsewswztwxxssc-ad64bbac-e0d5-4286-9b77-d008e8c8d419.jpg)

## 网络层和传输层有什么区别

> 阿里云

网络层和传输层都是计算机网络中的重要层次，它们在网络协议栈中扮演着不同的角色，主要区别如下：

1. 功能不同：网络层主要负责网络间的通信，为分组交换网上的数据报文提供端到端的传输服务；传输层则是为应用程序提供端到端的可靠数据传输服务，通过在端系统上运行的进程之间进行通信。
2. 协议不同：网络层主要使用的协议是 IP 协议（Internet Protocol），负责将网络中的数据报进行路由选择和传输；而传输层则包括了 TCP 协议（Transmission Control Protocol）和 UDP 协议（User Datagram Protocol），其中 TCP 提供面向连接的可靠传输服务，UDP 则提供面向无连接的不可靠传输服务。
3. 通信对象不同：网络层面向的是不同的网络之间的通信，它的通信对象是主机（或路由器）之间的通信；传输层则面向的是不同主机上的进程之间的通信，它的通信对象是运行在不同主机上的进程。
4. 数据单元不同：网络层的数据单元是 IP 数据报（Packet），是网络传输的最小数据单元；传输层的数据单元是 TCP 段（Segment）和 UDP 数据报（Datagram），是端到端传输的最小数据单元。

总体而言，网络层主要负责的是网络间的数据传输，而传输层则主要负责的是应用程序之间的数据传输，两者在网络协议栈中属于不同的层次，各司其职，相互配合，共同构成了计算机网络体系结构的基础。

## TCP 三次握手和四次挥手

> 蔚来，zoom，百度，腾讯，字节，腾讯IEG，快手，阿里，唯品会，蚂蚁

### 建立连接-TCP 三次握手

> 蚂蚁，阿里，美团

![TCP 三次握手图解](https://guide-blog-images.oss-cn-shenzhen.aliyuncs.com/github/javaguide/cs-basics/network/tcp-shakes-hands-three-times.png)

建立一个 TCP 连接需要“三次握手”，缺一不可 ：

- **一次握手**:客户端发送带有 SYN（SEQ=x） 标志的数据包 -> 服务端，然后客户端进入 **SYN_SEND** 状态，等待服务器的确认；
- **二次握手**:服务端发送带有 SYN+ACK(SEQ=y,ACK=x+1) 标志的数据包 –> 客户端,然后服务端进入 **SYN_RECV** 状态
- **三次握手**:客户端发送带有带有 ACK(ACK=y+1) 标志的数据包 –> 服务端，然后客户端和服务器端都进入**ESTABLISHED** 状态，完成TCP三次握手。

**当建立了 3 次握手之后，客户端和服务端就可以传输数据啦！**

#### 为什么要三次握手?

> 小米，开云集致，美团，阿里

三次握手的目的是建立可靠的通信信道，说到通讯，简单来说就是数据的发送与接收，而三次握手最主要的目的就是双方确认自己与对方的发送与接收是正常的。

1. **第一次握手** ：Client 什么都不能确认；Server 确认了对方发送正常，自己接收正常
2. **第二次握手** ：Client 确认了：自己发送、接收正常，对方发送、接收正常；Server 确认了：对方发送正常，自己接收正常
3. **第三次握手** ：Client 确认了：自己发送、接收正常，对方发送、接收正常；Server 确认了：自己发送、接收正常，对方发送、接收正常

三次握手就能确认双方收发功能都正常，缺一不可。

#### 第2次握手传回了ACK，为什么还要传回SYN？

服务端传回发送端所发送的 ACK 是为了告诉客户端：“我接收到的信息确实就是你所发送的信号了”，这表明从客户端到服务端的通信是正常的。回传 SYN 则是为了建立并确认从服务端到客户端的通信。

> SYN 同步序列编号(Synchronize Sequence Numbers) 是 TCP/IP 建立连接时使用的握手信号。在客户机和服务器之间建立正常的 TCP 网络连接时，客户机首先发出一个 SYN 消息，服务器使用 SYN-ACK 应答表示接收到了这个消息，最后客户机再以 ACK(Acknowledgement）消息响应。这样在客户机和服务器之间才能建立起可靠的 TCP 连接，数据才可以在客户机和服务器之间传递。

### 断开连接-TCP 四次挥手

> 字节，阿里云，小米

![TCP 四次挥手图解](https://guide-blog-images.oss-cn-shenzhen.aliyuncs.com/github/javaguide/cs-basics/network/tcp-waves-four-times.png)

断开一个 TCP 连接则需要“四次挥手”，缺一不可 ：

1. **第一次挥手** ：客户端发送一个 FIN（SEQ=X） 标志的数据包->服务端，用来关闭客户端到服务器的数据传送。然后，客户端进入 **FIN-WAIT-1** 状态。
2. **第二次挥手** ：服务器收到这个 FIN（SEQ=X） 标志的数据包，它发送一个 ACK （SEQ=X+1）标志的数据包->客户端 。然后，此时服务端进入**CLOSE-WAIT**状态，客户端进入**FIN-WAIT-2**状态。
3. **第三次挥手** ：服务端关闭与客户端的连接并发送一个 FIN (SEQ=y)标志的数据包->客户端请求关闭连接，然后，服务端进入**LAST-ACK**状态。
4. **第四次挥手** ：客户端发送 ACK (SEQ=y+1)标志的数据包->服务端并且进入**TIME-WAIT**状态，服务端在收到 ACK (SEQ=y+1)标志的数据包后进入 CLOSE 状态。此时，如果客户端等待 **2MSL** 后依然没有收到回复，就证明服务端已正常关闭，随后，客户端也可以关闭连接了。

**只要四次挥手没有结束，客户端和服务端就可以继续传输数据！**

#### 为什么要四次挥手？

> 开云集致

TCP是全双工通信，可以双向传输数据。任何一方都可以在数据传送结束后发出连接释放的通知，待对方确认后进入半关闭状态。当另一方也没有数据再发送的时候，则发出连接释放通知，对方确认后就完全关闭了 TCP 连接。

举个例子：A 和 B 打电话，通话即将结束后。

1. **第一次挥手** ： A 说“我没啥要说的了”
2. **第二次挥手** ：B 回答“我知道了”，但是 B 可能还会有要说的话，A 不能要求 B 跟着自己的节奏结束通话
3. **第三次挥手** ：于是 B 可能又巴拉巴拉说了一通，最后 B 说“我说完了”
4. **第四次挥手** ：A 回答“知道了”，这样通话才算结束。

#### 为什么不能把服务器发送的 ACK 和 FIN 合并起来，变成三次挥手？

因为服务器收到客户端断开连接的请求时，可能还有一些数据没有发完，这时先回复 ACK，表示接收到了断开连接的请求。等到数据发完之后再发 FIN，断开服务器到客户端的数据传送。

#### 如果第二次挥手时服务器的 ACK 没有送达客户端，会怎样？

客户端没有收到 ACK 确认，会重新发送 FIN 请求。

#### 为什么第四次挥手客户端需要等待 2*MSL（报文段最长寿命）时间后才进入 CLOSED 状态？

> 百度，开云集致，腾讯IEG，字节，小米

第四次挥手时，客户端发送给服务器的 ACK 有可能丢失，如果服务端因为某些原因而没有收到 ACK 的话，服务端就会重发 FIN，如果客户端在 2*MSL 的时间内收到了 FIN，就会重新发送 ACK 并再次等待 2MSL，防止 Server 没有收到 ACK 而不断重发 FIN。

> **MSL(Maximum Segment Lifetime)** : 一个片段在网络中最大的存活时间，2MSL 就是一个发送和一个回复所需的最大时间。如果直到 2MSL，Client 都没有再次收到 FIN，那么 Client 推断 ACK 已经被成功接收，则结束 TCP 连接。

## 服务端超时会重发第三次挥手数据包，具体等待多久算超时？

> 小米

在 TCP 中，通常采用一种名为 "指数退避算法"（Exponential Backoff Algorithm）的策略来计算超时时间。该算法会在每次超时后将等待时间逐渐增加，以避免网络拥塞等问题。

在 TCP 的传输控制块（Transmission Control Block, TCB）中通常会保存一个计时器，记录最后一次成功发送数据后已经过去的时间。在收到对方发来的第一个 FIN 包后，通常会在 TCB 中记录一个时间戳。如果在该时间戳之后，等待了一定时间仍未收到对方的 FIN 包，则会尝试重新发送 FIN 包。

根据 TCP 协议规定，超时重传时间通常从 1 秒开始，每次超时后将时间翻倍，直到最大超时时间（通常为 64 秒）。因此，在正常情况下，服务端等待 FIN 包的最长时间为 64 秒。但是，在实际应用中，可以根据网络环境和应用需求进行调整。

## 有太多time_wait状态怎么办?用什么命令去查看?

> 腾讯IEG

1.客户端，HTTP 请求的头部，connection 设置为 keep-alive，保持存活一段时间：现在的浏览器，一般都这么进行了

2.服务器端，

允许 time_wait 状态的 socket 被重用

缩减 time_wait 时间，设置为 1 MSL（即，2 mins）

## TCP 和 UDP 可以同时绑定相同的端口吗？

> 字节

可以的。

TCP 和 UDP 传输协议，在内核中是由两个完全独立的软件模块实现的。

当主机收到数据包后，可以在 IP 包头的「协议号」字段知道该数据包是 TCP/UDP，所以可以根据这个信息确定送给哪个模块（TCP/UDP）处理，送给 TCP/UDP 模块的报文根据「端口号」确定送给哪个应用程序处理。

因此， TCP/UDP 各自的端口号也相互独立，互不影响。

## TCP 与 UDP 的区别

> 邮储苏州研发，腾讯，字节，滴滴，华为，美团，阿里

1. **是否面向连接** ：UDP 在传送数据之前不需要先建立连接。而 TCP 提供面向连接的服务，在传送数据之前必须先建立连接，数据传送结束后要释放连接。
2. **是否是可靠传输**：远地主机在收到 UDP 报文后，不需要给出任何确认，并且不保证数据不丢失，不保证是否顺序到达。TCP 提供可靠的传输服务，TCP 在传递数据之前，会有三次握手来建立连接，而且在数据传递时，有确认、窗口、重传、拥塞控制机制。通过 TCP 连接传输的数据，无差错、不丢失、不重复、并且按序到达。
3. **是否有状态** ：这个和上面的“是否可靠传输”相对应。TCP 传输是有状态的，这个有状态说的是 TCP 会去记录自己发送消息的状态比如消息是否发送了、是否被接收了等等。为此 ，TCP 需要维持复杂的连接状态表。而 UDP 是无状态服务，简单来说就是不管发出去之后的事情了。
4. **传输效率** ：由于使用 TCP 进行传输的时候多了连接、确认、重传等机制，所以 TCP 的传输效率要比 UDP 低很多。
5. **传输形式** ： TCP 是面向字节流的，UDP 是面向报文的。
6. **首部开销** ：TCP 首部开销（20 ～ 60 字节）比 UDP 首部开销（8 字节）要大。
7. **是否提供广播或多播服务** ：TCP 只支持点对点通信，UDP 支持一对一、一对多、多对一、多对多；

## TCP 如何实现流量控制？

> 百度

**TCP 利用滑动窗口实现流量控制。流量控制是为了控制发送方发送速率，保证接收方来得及接收。** 接收方发送的确认报文中的窗口字段可以用来控制发送方窗口大小，从而影响发送方的发送速率。将窗口字段设置为 0，则发送方不能发送数据。

**为什么需要流量控制?** 这是因为双方在通信的时候，发送方的速率与接收方的速率是不一定相等，如果发送方的发送速率太快，会导致接收方处理不过来。如果接收方处理不过来的话，就只能把处理不过来的数据存在 **接收缓冲区(Receiving Buffers)** 里（失序的数据包也会被存放在缓存区里）。如果缓存区满了发送方还在狂发数据的话，接收方只能把收到的数据包丢掉。出现丢包问题的同时又疯狂浪费着珍贵的网络资源。因此，我们需要控制发送方的发送速率，让接收方与发送方处于一种动态平衡才好。

这里需要注意的是（常见误区）：

- 发送端不等同于客户端
- 接收端不等同于服务端

TCP 为全双工(Full-Duplex, FDX)通信，双方可以进行双向通信，客户端和服务端既可能是发送端又可能是服务端。因此，两端各有一个发送缓冲区与接收缓冲区，两端都各自维护一个发送窗口和一个接收窗口。接收窗口大小取决于应用、系统、硬件的限制（TCP传输速率不能大于应用的数据处理速率）。通信双方的发送窗口和接收窗口的要求相同

**TCP 发送窗口可以划分成四个部分** ：

1. 已经发送并且确认的TCP段（已经发送并确认）；
2. 已经发送但是没有确认的TCP段（已经发送未确认）；
3. 未发送但是接收方准备接收的TCP段（可以发送）；
4. 未发送并且接收方也并未准备接受的TCP段（不可发送）。

**TCP发送窗口结构图示** ：

![TCP发送窗口结构](https://guide-blog-images.oss-cn-shenzhen.aliyuncs.com/github/javaguide/cs-basics/network/tcp-send-window.png)

- **SND.WND** ：发送窗口。
- **SND.UNA**：Send Unacknowledged 指针，指向发送窗口的第一个字节。
- **SND.NXT**：Send Next 指针，指向可用窗口的第一个字节。

**可用窗口大小** = `SND.UNA + SND.WND - SND.NXT` 。

**TCP 接收窗口可以划分成三个部分** ：

1. 已经接收并且已经确认的 TCP 段（已经接收并确认）；
2. 等待接收且允许发送方发送 TCP 段（可以接收未确认）；
3. 不可接收且不允许发送方发送TCP段（不可接收）。

**TCP 接收窗口结构图示** ：

![TCP接收窗口结构](https://guide-blog-images.oss-cn-shenzhen.aliyuncs.com/github/javaguide/cs-basics/network/tcp-receive-window.png)

**接收窗口的大小是根据接收端处理数据的速度动态调整的。** 如果接收端读取数据快，接收窗口可能会扩大。 否则，它可能会缩小。

另外，这里的滑动窗口大小只是为了演示使用，实际窗口大小通常会远远大于这个值。

## TCP 的拥塞控制是怎么实现的？

> 百度，腾讯，字节tiktok，阿里云，蚂蚁

![TCP的拥塞控制](https://guide-blog-images.oss-cn-shenzhen.aliyuncs.com/github/javaguide/cs-basics/network/tcp-congestion-control.png)

为了进行拥塞控制，TCP 发送方要维持一个 **拥塞窗口(cwnd)** 的状态变量。拥塞控制窗口的大小取决于网络的拥塞程度，并且动态变化。发送方让自己的发送窗口等于拥塞窗口。

TCP 的拥塞控制采用了四种算法，即 **慢开始** 、 **拥塞避免** 、**快重传** 和 **快恢复**。在网络层也可以使路由器采用适当的分组丢弃策略（如主动队列管理 AQM），以减少网络拥塞的发生。

- **慢开始：** 慢开始算法的思路是当主机开始发送数据时，如果立即把大量数据字节注入到网络，那么可能会引起网络阻塞，因为现在还不知道网络的符合情况。经验表明，较好的方法是先探测一下，即由小到大逐渐增大发送窗口，也就是由小到大逐渐增大拥塞窗口数值。cwnd 初始值为 1，每经过一个传播轮次，cwnd 加倍。
- **拥塞避免：** 拥塞避免算法的思路是让拥塞窗口 cwnd 缓慢增大，即每经过一个往返时间 RTT 就把发送方的 cwnd 加 1.
- **快重传：** 采用快重传算法可以让发送方尽早知道发生了个别报文段的丢失。快重传算法首先要求接收方不要等待自己发送数据时才进行捎带确认，而是要立即发送确认，即使收到了失序的报文段也要立即发出对已收到的报文段的重复确认。发送方只要一连收到3个重复确认，就知道接收方确实没收到报文段，因而应当立即进行重传（即“快重传“），这样就不会出现超时，发送发也就不会误认为出现了网络拥塞。
- **快恢复：**发送方调整门限值ssthresh=cwnd/2，同时设置拥塞窗口cwnd=ssthresh，并开始执行拥塞避免算法。

------

## TCP 如何保证传输的可靠性？

> 腾讯，快手

1. **基于数据块传输** ：应用数据被分割成 TCP 认为最适合发送的数据块，再传输给网络层，数据块被称为报文段或段。
2. **对失序数据包重新排序以及去重**：TCP 为了保证不发生丢包，就给每个包一个序列号，有了序列号能够将接收到的数据根据序列号排序，并且去掉重复序列号的数据就可以实现数据包去重。
3. **校验和** : TCP 将保持它首部和数据的检验和。这是一个端到端的检验和，目的是检测数据在传输过程中的任何变化。如果收到段的检验和有差错，TCP 将丢弃这个报文段和不确认收到此报文段。
4. **超时重传** : 当发送方发送数据之后，它启动一个定时器，等待目的端确认收到这个报文段。接收端实体对已成功收到的包发回一个相应的确认信息（ACK）。如果发送端实体在合理的往返时延（RTT）内未收到确认消息，那么对应的数据包就被假设为[已丢失open in new window](https://zh.wikipedia.org/wiki/丢包)并进行重传。
5. **流量控制** : TCP 连接的每一方都有固定大小的缓冲空间，TCP 的接收端只允许发送端发送接收端缓冲区能接纳的数据。当接收方来不及处理发送方的数据，能提示发送方降低发送的速率，防止包丢失。TCP 使用的流量控制协议是可变大小的滑动窗口协议（TCP 利用滑动窗口实现流量控制）。
6. **拥塞控制** : 当网络拥塞时，减少数据的发送。

## 如何用udp设计出一个跟tcp一样安全可靠的协议

> 阿里

UDP（用户数据报协议）是一种面向无连接的传输协议，它不保证数据的可靠性、顺序性和重复性。相比之下，TCP（传输控制协议）是一种面向连接的协议，它提供了可靠的数据传输、流量控制、拥塞控制和错误恢复等功能。因此，如果想要设计一个跟TCP一样安全可靠的协议，需要在UDP上添加类似于TCP的机制。

以下是一些可能的方法：

1. 应用层添加可靠性机制

可以在应用层上实现可靠性机制，例如：发送方在发送数据时，将数据进行分片，并为每个分片添加一个序号和校验和。接收方在接收到数据时，根据序号和校验和进行验证，并在需要时重传丢失的分片。这种机制可以增强数据的可靠性和顺序性，但是也会增加网络延迟和带宽占用。

2. 基于UDP的可靠数据传输（UDT）

UDT是一种基于UDP的可靠数据传输协议，它提供了与TCP相似的可靠数据传输、流量控制、拥塞控制和错误恢复等功能。UDT通过在UDP的基础上添加自己的可靠性机制来实现这些功能，例如：数据分片、校验和、确认和重传机制等。UDT的优点是可以在不改变应用程序代码的情况下实现可靠数据传输，但是也会增加网络延迟和带宽占用。

3. 应用层加密和身份验证

为了确保数据的安全性，可以在应用层上添加加密和身份验证机制。例如：发送方可以使用公钥加密算法对数据进行加密，并将密钥传递给接收方。接收方在收到数据后，使用私钥解密数据，并根据发送方的身份验证数据的真实性。这种机制可以确保数据的安全性和完整性，但是也会增加计算和通信的开销。

总之，要设计一个跟TCP一样安全可靠的协议，需要在UDP上添加可靠性机制、拥塞控制、错误恢复、加密和身份验证等功能。不同的应用场景需要不同的协议设计方案，需要根据具体的需求来选择适合的方案。

## 从输入URL 到页面展示到底发生了什么？

> zoom，小米，字节，蚂蚁，度小满，唯品会，美团，蚂蚁

1. DNS 解析：浏览器通过DNS解析获取URL中的域名对应的IP地址。
2. 发起TCP连接：浏览器向服务器发起TCP连接请求，经过三次握手建立连接。
3. 发送HTTP请求：浏览器向服务器发送HTTP请求，请求中包含请求方法、请求头、请求体等信息。
4. 服务器处理请求并返回HTTP响应：服务器接收到请求后，处理请求并生成HTTP响应。响应中包含响应状态码、响应头、响应体等信息。
5. 浏览器解析响应内容：浏览器接收到响应后，根据响应头中的Content-Type类型来决定如何解析响应体中的内容。
6. 关闭TCP连接：浏览器接收到响应后，关闭TCP连接，断开与服务器的连接。
7. 渲染页面：浏览器根据响应内容和解析结果渲染页面，显示网页。

## 一次完整的http请求的过程

> 美团

一个完整的HTTP请求的过程通常涉及以下步骤：

1. DNS解析：当用户在浏览器中输入URL时，浏览器首先会检查本地DNS缓存以获取域名对应的IP地址。如果未找到，则会将请求发送给本地DNS服务器进行解析。
2. 建立TCP连接：一旦浏览器获取了服务器的IP地址，它将与服务器建立TCP连接。这需要进行三次握手，以确保数据传输的可靠性。
3. 发送HTTP请求：在TCP连接建立后，浏览器会向服务器发送HTTP请求。请求包括请求方法（GET、POST、PUT等）、请求头和请求正文（如果是POST请求）。
4. 服务器响应：一旦服务器接收到HTTP请求，它会根据请求内容做出响应。响应包括响应状态码、响应头和响应正文。
5. 接收HTTP响应：浏览器将接收到的响应存储在缓存中，并根据响应头信息来决定如何处理响应正文。
6. 关闭TCP连接：一旦HTTP响应完成，浏览器会关闭与服务器的TCP连接。这需要进行四次握手，以确保数据传输的完整性。
7. 渲染页面：如果响应正文是HTML文档，浏览器将解析HTML代码，并将其转换为可视化的页面。在这个过程中，浏览器还会根据CSS样式和JavaScript代码来渲染页面。

总的来说，这是一个从浏览器到服务器，然后从服务器到浏览器的过程，其中包括多个步骤来确保数据传输的可靠性和完整性，以及页面的正确渲染。

## DNS解析的过程

> 字节

DNS（Domain Name System）是一种将域名（如www.example.com）转换为IP地址的分布式命名系统。当用户在浏览器中输入域名时，浏览器会通过DNS来解析域名对应的IP地址，然后建立与该IP地址对应的服务器的连接，最终获取所需的网页内容。

DNS解析的过程大致如下：

1. 用户在浏览器中输入域名，浏览器会首先查询本地缓存，如果本地缓存中存在该域名对应的IP地址，则直接返回IP地址，否则进行下一步操作。
2. 浏览器向本地DNS服务器发送DNS解析请求，本地DNS服务器通常由ISP（Internet Service Provider，互联网服务提供商）提供，负责缓存DNS解析结果，以减轻DNS服务器的负担。
3. 如果本地DNS服务器缓存中存在该域名对应的IP地址，则直接返回IP地址，否则向根DNS服务器发送请求。
4. 根DNS服务器返回顶级域名服务器（如.com、.cn等）的地址，本地DNS服务器向顶级域名服务器发送请求。
5. 顶级域名服务器返回该域名所在的权威DNS服务器的地址，本地DNS服务器向权威DNS服务器发送请求。
6. 权威DNS服务器返回该域名对应的IP地址，本地DNS服务器将该地址保存到缓存中，并将地址返回给浏览器。
7. 浏览器得到IP地址后，建立与该地址对应的服务器的连接，并向服务器发送HTTP请求，最终获取所需的网页内容。

DNS解析的过程可能会涉及多次网络通信和多个DNS服务器的协作，因此解析的时间可能会比较长。为了提高DNS解析的效率，可以使用本地缓存、增加DNS服务器的数量等方式进行优化。

## HTTP协议的特点

> 美团

HTTP（Hypertext Transfer Protocol）是一种应用层协议，用于在客户端和服务器之间传输超文本。

HTTP协议的特点包括：

1. 无连接：每次请求都需要建立一个新的连接，服务器完成请求后立即断开连接，客户端和服务器不保持连接状态，这样可以减少服务器的负担，但是每次连接都需要重新建立，也会增加一定的开销。
2. 无状态：HTTP协议是无状态的，即每个请求都是独立的，服务器不会记录客户端的状态。这样可以提高服务器的吞吐量，但也会导致服务器不能区分两个请求是否来自同一客户端，也无法记录客户端的历史信息。
3. 支持多种媒体类型：HTTP协议支持多种不同的数据格式，如文本、图片、音频、视频等。
4. 请求-响应模式：HTTP协议是基于请求-响应模式的，客户端发送请求，服务器返回响应。
5. 简单：HTTP协议采用简单的请求-响应模式，使得它比较容易实现和理解。

综上所述，HTTP协议是无状态的，即每个请求都是独立的，服务器不会记录客户端的状态。因此，HTTP协议通常需要使用cookie和session等机制来维护客户端的状态。

## http长连接

> 美团

HTTP长连接（HTTP Keep-Alive）是指在一次TCP连接中可以传送多个HTTP请求和响应，而不是在每个请求和响应之后都断开连接，从而减少了TCP连接的建立和关闭所需的时间和资源。

在HTTP长连接中，客户端在发送HTTP请求时会在请求头中包含一个`Connection: keep-alive`的字段，告诉服务器要保持长连接。如果服务器也支持HTTP长连接，它会在响应头中包含一个`Connection: keep-alive`的字段，以便告诉客户端它可以在同一TCP连接上处理更多的请求。

在HTTP长连接中，客户端和服务器可以在同一TCP连接上发送和接收多个HTTP请求和响应，从而减少了连接的建立和关闭时间，减少了网络延迟和资源消耗，提高了HTTP协议的性能。同时，HTTP长连接也有一些缺点，如连接可能被意外中断，服务器资源可能被长时间占用，等待时间可能会增加等。因此，HTTP长连接需要谨慎使用，需要根据实际情况进行调整。

## HTTP 和 HTTPS 有什么区别？

> 小米，腾讯，阿里，字节，华为，美团，阿里云，蚂蚁

1. 安全性：HTTPS比HTTP更安全，因为它使用TLS/SSL协议来加密数据传输，可以防止黑客窃听、数据篡改和数据泄露等安全问题。
2. 端口号：HTTP默认使用端口号80，而HTTPS默认使用端口号443。
3. 证书：HTTPS需要使用数字证书来验证网站身份，这可以保证用户与正确的网站建立连接，防止钓鱼攻击等安全问题。
4. 速度：HTTPS传输的数据需要加密和解密，所以比HTTP稍微慢一些。

## ssl/tls协议怎么实现加密的？

> 阿里，腾讯

SSL和TLS都是一种协议，用于在客户端和服务器之间建立加密通道，确保数据传输的机密性、完整性和可验证性。其基本原理是使用公钥加密算法来确保数据传输的安全性。具体实现步骤如下：

1. 客户端向服务器发送HTTPS请求。
2. 服务器返回自己的SSL/TLS证书给客户端，包括证书的公钥和证书签名等信息。
3. 客户端验证服务器的证书，确认其合法性。
4. 客户端生成一个随机的对称加密密钥，并使用服务器的公钥进行加密，将加密后的密钥发送给服务器。
5. 服务器使用私钥解密客户端发来的对称加密密钥。
6. 客户端和服务器使用对称加密算法对传输的数据进行加密和解密。

这种机制的优点在于，每个连接都使用一个新的对称密钥，从而保证了每个连接的独立性和安全性。此外，由于公钥加密算法的特点，只有私钥的持有者才能解密数据，因此可以保证数据传输的安全性。

## http1.1和http2.0的区别

> 阿里，字节

1. 多路复用：HTTP/2.0 引入了多路复用，允许客户端在同一个连接上发送多个请求。在 HTTP/1.1 中，每个请求都需要建立一个新的连接。这使得 HTTP/2.0 更加高效和快速。
2. 二进制传输：HTTP/2.0 使用二进制传输格式，而 HTTP/1.1 使用文本格式。二进制格式更加紧凑，可以减少数据传输量和响应时间。
3. 数据流和帧：HTTP/2.0将请求和响应划分为多个数据流，每个数据流可以由多个数据帧组成，这样可以更加灵活地管理数据。
4. 头部压缩：HTTP/2.0 支持头部压缩，减少了传输的头部大小，从而减少了网络带宽的使用。在 HTTP/1.1 中，每个请求都需要重复发送大量的头部信息。
5. 服务器推送：HTTP/2.0 支持服务器主动推送，可以在客户端请求之前将资源推送给客户端。这可以减少延迟和提高性能。
6. 流量控制：HTTP/2.0 支持流量控制，可以优化资源的使用。在 HTTP/1.1 中，每个请求都需要使用相同的连接和带宽。

## http1.0和http1.1的区别？

> 阿里，蔚来

1. 持久连接(Persistent Connections)： HTTP/1.0 中每次请求都需要建立一次连接和断开连接，而 HTTP/1.1 引入了持久连接，允许多个请求和响应使用同一条连接。这样就减少了每个请求所需的时间，提高了性能。
2. 流水线(Pipeline)： HTTP/1.1 可以同时在一个连接中发送多个请求，而不需要等待先前的响应。这个特性叫做流水线，可以减少网络延迟，提高性能。
3. Host 头部(Host Header)： HTTP/1.1 要求在请求头中必须包含 Host 头部，以便服务器能够处理多个虚拟主机。
4. 缓存机制(Caching)： HTTP/1.1 引入了更加灵活的缓存机制，允许代理服务器和客户端缓存响应，从而减少了对服务器的请求次数，提高了性能。
5. 错误处理(Error Handling)： HTTP/1.1 对错误处理做了一些改进，引入了新的状态码以及对错误处理的更好支持。
6. 带宽优化(Bandwidth Optimization)： HTTP/1.1 引入了一些新的压缩方法，如 gzip，可以减少网络传输中的数据量，从而提高性能。

## HTTP3.0用的什么传输层协议

> 蔚来

HTTP/3.0使用的传输层协议是QUIC（Quick UDP Internet Connections），这是一种基于UDP协议的传输层协议。QUIC由Google开发，旨在解决TCP的一些限制和缺陷，并提供更好的性能和安全性。QUIC使用加密来保护数据传输的机密性和完整性，并使用多路复用（Multiplexing）技术将多个HTTP请求同时发送到服务器，从而提高了网络传输效率。HTTP/3.0的实现需要在传输层上支持QUIC协议。

## PUT 和 POST 提交有什么区别？

> zoom

put满足幂等性，post不满足幂等性

## http get和post区别

> 字节

HTTP协议中的GET和POST是两种常用的请求方法，它们的主要区别如下：

1. 请求参数传递方式不同

GET请求将参数放在URL的后面，以?分隔URL和参数，多个参数之间用&连接。例如：

```
http://www.example.com/search?q=keyword&page=1
```

POST请求将参数放在请求体中，不会像GET请求一样将参数明文暴露在URL中。例如：

```
POST /login HTTP/1.1
Host: www.example.com
Content-Type: application/x-www-form-urlencoded
Content-Length: 16

username=admin&password=123456
```

2. 数据传输大小限制不同

GET请求的数据传输大小有限制，具体取决于浏览器和服务器的限制，一般不能超过2KB，否则可能被浏览器截断。POST请求的数据传输大小理论上无限制，但是实际上受到服务器和网络带宽等因素的限制。

3. 数据传输安全性不同

GET请求的数据传输是明文传输，将参数放在URL中，容易被拦截、篡改，安全性较差。POST请求的数据传输是加密传输，将参数放在请求体中，安全性较高。

4. 对请求的幂等性要求不同

GET请求是幂等的，即无论请求多少次，对服务器数据的影响都是一样的。POST请求不是幂等的，多次提交同样的请求可能会产生不同的结果，对服务器数据的影响也可能不同。

综上所述，GET和POST的使用场景是不同的。一般来说，GET请求适合获取数据，不会改变服务器端的数据；POST请求适合提交数据，会改变服务器端的数据。

## HTTP 与 TCP 区别

> 字节

- HTTP 对应于应用层，TCP 协议对应于传输层
- HTTP 协议是在 TCP 协议之上建立的，HTTP 在发起请求时通过 TCP 协议建立起连接服务器的通道，请求结束后，立即断开 TCP 连接
- HTTP 是无状态的短连接，而 TCP 是有状态的长连接
- TCP是传输层协议，定义的是数据传输和连接方式的规范，HTTP是应用层协议，定义的是传输数据的内容的规范

## tcp和http的keep-alive

> 字节

TCP keep-alive和HTTP keep-alive是两个不同的概念。

TCP keep-alive是一种TCP协议的机制，用于检测长时间处于空闲状态的连接是否仍然有效。当一个TCP连接在一段时间内没有发送或接收数据时，TCP keep-alive机制会发送一个空的数据包给对端，如果对端正常应答，则连接仍然有效，否则连接将被关闭。TCP keep-alive可以避免因网络故障或其他原因导致的连接意外断开。

HTTP keep-alive是一种HTTP协议的机制，用于在一次TCP连接中传输多个HTTP请求和响应。在HTTP keep-alive机制下，客户端在发送完一个HTTP请求后，不关闭TCP连接，而是继续使用这个TCP连接发送下一个HTTP请求，服务器也不关闭TCP连接，而是将多个HTTP响应依次返回给客户端。这样可以避免在每次HTTP请求和响应之间建立和关闭TCP连接的开销，提高HTTP请求的响应速度和性能。

需要注意的是，HTTP keep-alive需要在TCP keep-alive机制的支持下才能生效。因为TCP keep-alive机制可以检测到网络故障等情况下的连接状态，而HTTP keep-alive机制只是在长时间没有HTTP请求和响应时保持TCP连接不关闭，如果发生网络故障等情况，TCP keep-alive机制仍然会关闭连接。

## 输入一个网址如www.bytedance.com，没有带http或者https，是怎么变成https的？

> 字节

如果浏览器输入的URL没有带上协议（http或https），浏览器会默认使用http协议，对应的默认端口是80。但是对于现代浏览器，它们会尝试自动将http转为https，这种行为叫做HTTP Strict Transport Security (HSTS)，它是一种安全机制。

当浏览器第一次访问一个网站时，如果网站返回了Strict-Transport-Security头部，浏览器就会记住这个头部的值，并在之后的访问中自动将http请求转为https请求。如果网站支持https，那么就会连接到443端口，否则浏览器会显示无法访问该网站。如果要访问的网站没有启用HSTS机制，那么浏览器就会默认使用http协议连接80端口。

## HTTP 报文结构

> 滴滴治理，美团

HTTP报文由报文头部（Headers）和报文主体（Body）两部分组成，其基本结构如下：

```html
<Method> <URL> <HTTP Version>
<Headers>

<Body>
```

其中，`<Method>` 指的是HTTP方法，比如GET、POST等； `<URL>` 是请求的地址； `<HTTP Version>` 表示使用的HTTP协议版本，比如HTTP/1.1； `<Headers>` 包含了HTTP请求或响应的头部信息，如`Content-Type`、`User-Agent`、`Cookie`等； `<Body>` 是可选的，包含了HTTP请求或响应的实体内容。

HTTP请求报文的基本格式如下：

```html
GET /index.html HTTP/1.1
Host: www.example.com
User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:87.0) Gecko/20100101 Firefox/87.0
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8
Accept-Language: en-US,en;q=0.5
Accept-Encoding: gzip, deflate, br
Connection: keep-alive
Referer: https://www.example.com/
Cookie: sessionid=abcdef1234567890

<Body>
```

HTTP响应报文的基本格式如下：

```html
HTTP/1.1 200 OK
Date: Thu, 17 Mar 2023 10:00:00 GMT
Content-Type: text/html; charset=UTF-8
Content-Length: 12345
Connection: keep-alive
Server: Apache/2.4.41 (Ubuntu)

<Body>
```

其中，HTTP响应报文的第一行为状态行，包含了HTTP协议版本、状态码和状态描述； `<Headers>` 中包含了HTTP响应的头部信息，如`Content-Type`、`Content-Length`、`Server`等； `<Body>` 是响应的实体内容。

## HTTP 常见状态码

> 腾讯IEG，字节，zoom，蚂蚁

### 1xx Informational（信息性状态码）

信息提示，表示请求已经接收，继续处理。

### 2xx Success（成功状态码）

- **200 OK** ：请求被成功处理。比如我们发送一个查询用户数据的HTTP 请求到服务端，服务端正确返回了用户数据。这个是我们平时最常见的一个 HTTP 状态码。
- **201 Created** ：请求被成功处理并且在服务端创建了一个新的资源。比如我们通过 POST 请求创建一个新的用户。
- **202 Accepted** ：服务端已经接收到了请求，但是还未处理。
- **204 No Content** ： 服务端已经成功处理了请求，但是没有返回任何内容。

### 3xx Redirection（重定向状态码）

- **301 Moved Permanently** ： 资源被永久重定向了。比如你的网站的网址更换了。
- **302 Found** ：资源被临时重定向了。比如你的网站的某些资源被暂时转移到另外一个网址。

### 4xx Client Error（客户端错误状态码）

- **400 Bad Request** ： 发送的HTTP请求存在问题。比如请求参数不合法、请求方法错误。
- **401 Unauthorized** ： 请求未经授权，需要进行身份验证，认证之后才能访问的资源。
- **403 Forbidden** ：表示你不具有访问请求的资源的权限，直接拒绝HTTP请求，不处理。一般用来针对非法请求。
- **404 Not Found** ： 你请求的资源未在服务端找到。比如你请求某个用户的信息，服务端并没有找到指定的用户。
- **409 Conflict** ： 表示请求的资源与服务端当前的状态存在冲突，请求无法被处理。

### 5xx Server Error（服务端错误状态码）

- **500 Internal Server Error** ： 服务端出问题了（通常是服务端出Bug了）。比如你服务端处理请求的时候突然抛出异常，但是异常并未在服务端被正确处理。

- **502 Bad Gateway** ：通常表示反向代理服务器无法从上游服务器（如应用服务器）收到有效响应，即代理服务器无法完成对请求的处理。

  具体地说，当代理服务器收到请求后，会将请求转发给应用服务器，如果应用服务器无法正常响应或者响应超时，则代理服务器无法得到有效的响应，此时就会返回502 Bad Gateway状态码给客户端。

  通常，这种情况可能是因为应用服务器崩溃、网络连接异常或代理服务器配置错误等原因导致的。

- **503 Service Unavailable**：服务器暂时无法处理请求，一段时间后可能恢复正常。

------

## 正向代理和反向代理

> 百度

### 本质区别

正向代理中，服务器并不知道真正的客户端到底是谁；而在反向代理中，客户端也不知道真正的服务器是谁

### 图解

- 正向代理的主动方是用户，主要用来解决`跨域`问题，还有`隐藏`用户访问记录的作用

![image.png](https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/d23f213bc52d4141b435954eb4035157~tplv-k3u1fbpfcp-zoom-in-crop-mark:4536:0:0:0.image?)

- 反向代理的主动方是服务器，主要是提供`负载均衡`、`安全防护`等作用

![image.png](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/9c0d545c42834f3fabf61b4222fbe6d5~tplv-k3u1fbpfcp-zoom-in-crop-mark:4536:0:0:0.image?)

### 作用层面上的区别

- 正向代理主要用来解决`跨域`问题，还有`隐藏`用户访问记录的作用
- 反向代理主要是提供`负载均衡`、`安全防护`等作用

#### 为什么正向代理可以解决跨域问题

因为服务器之间不需要遵循同源策略

#### 为什么正向代理可以隐藏用户访问记录

因为正向代理中服务器根本不知道访问服务器资源的是具体哪位用户，服务器无法获知用户的真实 IP 地址

#### 为什么反向代理可以提供负载均衡的作用

- 客户端发送的（Nginx 反向代理服务器接收到）的请求数量，就是我们说的`负载量`
- 按照一定的规则将请求数量分发到不同的服务器处理，就是一种`均衡`

所以，`将服务器接收到的请求按照一定规则分发`的过程，称为**负载均衡**

这就是 `CDN` 的核心技术原理

#### 为什么反向代理可以提供安全防护的作用

实际上正向代理也可以提供安全防护功能，也就是说代理可以实现安全防护，原理如下：

如果用户B被列入黑名单，则可以借助代理服务器对其请求进行拦截

## 负载均衡常用算法

> 百度

**1. 轮询 （round-robin）**

轮询为负载均衡中较为基础也较为简单的算法，它不需要配置额外参数。假设配置文件中共有 **M** 台服务器，该算法遍历服务器节点列表，并按节点次序每轮选择一台服务器处理请求。当所有节点均被调用过一次后，该算法将从第一个节点开始重新一轮遍历。

**特点**：由于该算法中每个请求按时间顺序逐一分配到不同的服务器处理，因此适用于服务器性能相近的集群情况，其中每个服务器承载相同的负载。但对于服务器性能不同的集群而言，该算法容易引发资源分配不合理等问题。

**2、加权轮询**

为了避免普通轮询带来的弊端，加权轮询应运而生。在加权轮询中，每个服务器会有各自的 `weight`。一般情况下，`weight` 的值越大意味着该服务器的性能越好，可以承载更多的请求。该算法中，客户端的请求按权值比例分配，当一个请求到达时，优先为其分配权值最大的服务器。

**特点**：加权轮询可以应用于服务器性能不等的集群中，使资源分配更加合理化。

Nginx 加权轮询源码可见：[ngx_http_upstream_round_robin.c](https://link.juejin.cn?target=https%3A%2F%2Fgithub.com%2Fnginx%2Fnginx%2Fblob%2Fmaster%2Fsrc%2Fhttp%2Fngx_http_upstream_round_robin.c)，源码分析可参考：[关于轮询策略原理的自我理解](https://link.juejin.cn?target=https%3A%2F%2Fblog.csdn.net%2FBlacksunAcheron%2Farticle%2Fdetails%2F84439302)。其核心思想是，遍历各服务器节点，并计算节点权值，计算规则为 `current_weight` 与其对应的 `effective_weight` 之和，每轮遍历中选出权值最大的节点作为最优服务器节点。其中 `effective_weight` 会在算法的执行过程中随资源情况和响应情况而改变。较为核心的部分如下：

```ini
for (peer = rrp->peers->peer, i = 0;
	peer; 	/* peer 为当前遍历的服务器结点*/
  peer = peer->next, i++)
{
  ...
    
	/* 每轮遍历会更新 peer 当前的权值*/
	peer->current_weight += peer->effective_weight;

  ...
    
	/* best 为当前服务器中的最优节点，即本轮中选中的服务器节点*/
	if (best == NULL || peer->current_weight > best->current_weight) {
		best = peer;
  	p = i;
	}
  
  ...
}
复制代码
```

**3. IP 哈希（IP hash）**

`ip_hash` 依据发出请求的客户端 IP 的 hash 值来分配服务器，该算法可以保证同 IP 发出的请求映射到同一服务器，或者具有相同 hash 值的不同 IP 映射到同一服务器。

**特点**：该算法在一定程度上解决了集群部署环境下 Session 不共享的问题。

> Session 不共享问题是说，假设用户已经登录过，此时发出的请求被分配到了 A 服务器，但 A 服务器突然宕机，用户的请求则会被转发到 B 服务器。但由于 Session 不共享，B 无法直接读取用户的登录信息来继续执行其他操作。

实际应用中，我们可以利用 `ip_hash`，将一部分 IP 下的请求转发到运行新版本服务的服务器，另一部分转发到旧版本服务器上，实现灰度发布。再者，如遇到文件过大导致请求超时的情况，也可以利用 `ip_hash` 进行文件的分片上传，它可以保证同客户端发出的文件切片转发到同一服务器，利于其接收切片以及后续的文件合并操作。

**4、其他算法**

- URL hash

  `url_hash` 是根据请求的 URL 的 hash 值来分配服务器。该算法的特点是，相同 URL 的请求会分配给固定的服务器，当存在缓存的时候，效率一般较高。然而 Nginx 默认不支持这种负载均衡算法，需要依赖第三方库。

- 最小连接数（Least Connections）

  假设共有 ![M](https://juejin.cn/equation?tex=M) 台服务器，当有新的请求出现时，遍历服务器节点列表并选取其中连接数最小的一台服务器来响应当前请求。连接数可以理解为当前处理的请求数。

## tcp粘包及解决方式

> 百度，阿里云，蚂蚁

TCP粘包是指在TCP传输过程中，多个数据包被合并成一个大的数据包发送到接收端，这可能导致接收端无法正确解析数据包。常见的解决方式包括：

1. 基于消息长度的粘包处理：在消息头部添加消息长度字段，接收方在接收到数据后先读取消息长度，再根据长度读取完整消息。这种方法适用于消息大小固定或者能够提前知道消息大小的情况。
2. 基于消息边界的粘包处理：在消息中添加特殊的分隔符，接收方根据分隔符将消息拆分为多个独立的消息。例如，在HTTP协议中使用“\r\n”作为消息分隔符。
3. 使用固定长度的缓冲区：在接收端使用固定长度的缓冲区，当接收到的数据长度超过缓冲区长度时，将缓冲区中的数据先处理，再处理剩余数据。
4. 应用层协议处理：在应用层协议中添加消息编号或者时间戳等字段，接收方通过这些字段判断是否为同一个消息。

## Cookie与Session的区别

> 美团，蚂蚁，阿里

Cookie和Session都是Web应用程序中用于维护用户状态的机制，但它们有以下几个不同点：

1. 存储位置：Cookie是存储在客户端浏览器中的一小段文本，而Session是存储在服务器端的一段数据。
2. 存储内容：Cookie主要用于存储客户端的身份认证信息和用户偏好设置等数据，而Session则可以存储任何类型的数据，如用户的购物车信息、表单数据等。
3. 安全性：Cookie中存储的信息可以被客户端浏览器篡改或伪造，因此不适合存储敏感信息，如密码等；而Session存储在服务器端，客户端无法篡改或伪造，因此比Cookie更加安全。
4. 大小限制：Cookie的大小通常受到浏览器和服务器的限制，一般不超过4KB，而Session可以存储更多的数据。
5. 生命周期：Cookie可以设置过期时间，可以在浏览器关闭后仍然存在，而Session的生命周期通常是与用户会话相关的，一旦用户关闭浏览器或超时，Session数据就会被销毁。

综上所述，Cookie适用于存储较小的、不敏感的数据，如用户偏好设置、浏览记录等；而Session适用于存储较大的、敏感的数据，如用户购物车信息、登录状态等。在实际开发中，Cookie和Session通常会同时使用，以满足不同的需求。

## 使用Socket编程的流程

> 度小满

服务端：创建socket对象，bind端口，监听端口，accept（）阻塞等待获取连接对象的文件描述符，recv（）接收客户端发来的信息，close（）关闭socket对象；

客户端：创建socket对象，bind端口，connect（）连接指定ip端口的服务器，send（）数据信息，close（），关闭客户端；

## socket编程中客户端和服务端如何区分本次数据报文的结束

> 度小满

两者约定一个结束符，比如’/n‘，当读取到这个约定的结束符之后就认为本次信息报文结束；

## ping的原理

> 蚂蚁，阿里云

Ping是一个基于ICMP协议（Internet Control Message Protocol，互联网控制报文协议）的工具，用于测试主机之间是否可达、测量网络延迟和丢包率等。ICMP位于网络层的顶部，常被认为是IP协议的一个扩展，主要用于在IP网络中发送错误报告和简单的控制消息，如请求响应，主机重定向，路由器通告等。

Ping命令的原理是向目标主机发送ICMP数据报（通常是Echo请求报文），如果目标主机收到了这个报文，则会立即返回一个Echo应答报文。发送端会计算出从发送到接收所经过的时间（即延迟），并将其显示出来。如果目标主机没有收到Echo请求报文，则表示目标主机不可达或网络出现了问题。

在实际应用中，Ping命令可以用来测试本地网络和互联网之间的连接质量和速度，以及排查网络故障和定位网络瓶颈。但是需要注意的是，Ping命令在某些情况下可能会被防火墙或路由器过滤，因此在使用Ping命令时，需要保证网络连接畅通，避免误判或误导。同时，在进行Ping测试时，需要根据实际情况选择合适的参数和工具，以提高测试的精度和可靠性。

## VLAN

> 蚂蚁

VLAN，即Virtual LAN，是一种将物理上的网络划分成多个逻辑上的虚拟网络的技术。通过将不同的设备划分到不同的VLAN中，可以实现不同设备之间的逻辑隔离和安全控制。例如，可以将公司的服务器和打印机放在一个VLAN中，将公司的员工放在另一个VLAN中，从而实现服务器和打印机的逻辑隔离，保护公司的核心资源。

VLAN是通过交换机来实现的，交换机可以根据不同的VLAN对数据进行过滤和转发。具体来说，交换机可以通过VLAN ID来标记不同的VLAN，对于同一VLAN中的设备，交换机会将它们视为同一广播域中的设备，可以直接进行通信；对于不同VLAN中的设备，交换机会对它们之间的数据进行过滤，防止不同VLAN之间的设备直接通信。

在使用VLAN时，需要仔细设计VLAN的划分和规划，以避免出现网络拓扑复杂、管理困难、性能下降等问题。同时，需要确保交换机和其他网络设备的兼容性和稳定性，以确保网络的可靠性和安全性。

## 请介绍一下你的在线视频分享项目

本项目借鉴了youtube和bilibili的设计思想，是一个提供在线分享视频的平台。采用B2B2C的业务模式，向用户提供视频观看服务，up主通过平台完成视频上传的过程。本项目主要包括三类用户角色：普通用户、up主、平台运营人员。

业务流程：

1、up主登录视频管理平台，编辑视频信息，发布自己的视频。

2、平台运营人员登录运营平台审核视频信息，审核通过后视频方可发布。

3、视频发布后普通用户登录平台点击视频在线观看。免费视频可直接观看，收费视频需要下单购买。

具体模块：

1. 内容管理模块：内容管理由up主和平台的运营人员共同完成。

   up主的业务流程如下：

   1、登录up主账号。

   2、维护视频信息，添加一个视频需要编辑视频的基本信息、上传视频封面图片、视频简介、上传视频文件等内容。

   3、视频信息编辑完成，通过视频预览确认无误后提交视频审核。

   4、待运营人员视频审核通过后方可进行视频发布。

   运营人员的业务流程如下：

   1、查询待审核的视频信息。

   2、审核视频信息。

   3、提交审核结果。

2. 媒资管理模块：主要涉及到大文件上传，对于视频需要先进行分块，然后将分块上传到MinIO，上传后进行合并。如果视频格式不对的话需要进行转码。

3. 认证授权模块：

   1、提供统一认证入口。

   2、前端请求认证，认证通过颁发jwt令牌返给前端

   3、前端携带jwt令牌通过网关访问微服务。

   4、网关负责校验jwt令牌的合法性，微服务负责进行授权。

4. 视频订阅模块：视频订阅是将视频加入我的播放列表的过程。对免费视频订阅后可直接加入我的播放列表，对付费视频订阅后需要下单支付，支付成功后系统会自动将其加入我的播放列表。

5. 订单支付模块：当用户点击“微信支付”或支付宝支付时执行流程如下：

   1、请求学习中心服务创建视频订阅记录

   2、请求订单服务创建商品订单、生成支付二维码。

   3、用户扫码请求订单支付服务，订单支付服务请求第三方支付平台生成支付订单。

   4、前端唤起支付客户端，用户输入密码完成支付。

   5、第三方支付平台支付完成发起支付通知。

   6、订单支付服务接收支付通知结果并向视频订阅中心服务通知支付结果。

   7、视频订阅中心服务收到支付结果，如果支付成功则更新视频订阅记录，并添加到我的播放列表。

## 跨域问题（问题）

浏览器前端http://localhost:8601请求服务器后端http://localhost:63110/system/dictionary/all报错，被CORS policy阻止，因为没有Access-Control-Allow-Origin 头信息。CORS全称是 cross origin resource share 表示跨域资源共享。

浏览器的同源策略会去判断当前请求是否是跨域请求，同源策略是浏览器的一种安全机制，从一个地址请求另一个地址，如果协议、主机、端口三者只要有一个不一样就是跨域请求。

解决跨域的三种方法：

1、JSONP

通过script标签的src属性进行跨域请求，如果服务端要响应内容则首先读取请求参数callback的值，callback是一个回调函数的名称，服务端读取callback的值后将响应内容通过调用callback函数的方式告诉请求方。如下图：

![image-20220910104654414](E:\Typora\image-20220910104654414.png)

2、添加响应头（本项目采用的方式）

服务端在响应头添加 Access-Control-Allow-Origin：*

具体实现：配置一个过滤器GlobalCorsConfig，返回一个CorsFilter

3、通过nginx代理跨域

由于服务端之间没有跨域，浏览器通过nginx去访问跨域地址。

![image-20220910110012462](E:\Typora\image-20220910110012462.png)

## Gateway网关怎么用的？

本项目使用Spring Cloud Gateway作用网关，网关的作用是路由转发，见下图：

 

![img](E:\Typora\clip_image002-16770362870673.gif)

前端请求到Nginx，通过网关将请求转发至各个微服务。

网关进行路由时需要知道每个微服务实例的地址，网关从nacos读取服务地址，如下图：

 

![img](E:\Typora\clip_image004.gif)

流程如下：

1、微服务启动，将自己注册到Nacos，Nacos记录了各微服务实例的地址。

2、网关从Nacos读取服务列表，包括服务名称、服务地址等。

3、请求到达网关，网关将请求路由到具体的微服务。

本项目网关还具有统一鉴权功能：

1、网站白名单

在白名单的中的地址不进行身份校验直接放行。

2、身份校验

校验请求中jwt令牌的合法性，令牌合法则继续访问，否则拒绝访问。

## MinIO是什么，为什么要使用MinIO?

MinIO是一个轻量级的分布式文件系统，由多个MinIO节点连接组成，可根据文件规模进行扩展，适用于海量文件的存储与访问。

**MinIO有什么优势？**

1. MinIO开源，使用简单，功能强大
2. MinIO使用纠删码算法，只要不超过一般的节点坏掉整个文件系统就可以使用
3. 如果将坏的节点重新启动，自动恢复没有上传成功的节点

MinIO集群采用去中心化共享架构，每个结点是对等关系，通过Nginx可对MinIO进行负载均衡访问。

**去中心化有什么好处？**

在大数据领域，通常的设计理念都是无中心和分布式。Minio分布式模式可以帮助你搭建一个高可用的对象存储服务，你可以使用这些存储设备，而不用考虑其真实物理位置。

它将分布在不同服务器上的多块硬盘组成一个对象存储服务。由于硬盘分布在不同的节点上，分布式Minio避免了单点故障。如下图：

![img](E:\Typora\clip_image002-16770462661546.gif)

Minio使用纠删码技术来保护数据，它是一种恢复丢失和损坏数据的数学算法，它将数据分块冗余的分散存储在各各节点的磁盘上，所有的可用磁盘组成一个集合，上图由8块硬盘组成一个集合，当上传一个文件时会通过纠删码算法计算对文件进行分块存储，除了将文件本身分成4个数据块，还会生成4个校验块，数据块和校验块会分散的存储在这8块硬盘上。

使用纠删码的好处是即便丢失一半数量（N/2）的硬盘，仍然可以恢复数据。 比如上边集合中有4个以内的硬盘损害仍可保证数据恢复，不影响上传和下载，如果多于一半的硬盘坏了则无法恢复。

## 断点续传是怎么做的？（问题）

1、前端上传文件前请求媒资接口层检查文件是否存在，如果已经存在则不再上传。

2、如果文件在系统不存在则前端开始上传，首先对视频文件进行分块

3、前端分块进行上传，上传前首先检查分块是否上传，如已上传则不再上传，如果未上传则开始上传分块。

4、前端将分块上传完毕后接口层请求服务层合并分块。

5、服务层根据文件信息找到MinIO中的分块文件，下载到本地临时目录，将所有分块下载完毕后开始合并 。

6、合并完成将合并后的文件上传到MinIO。

## xxl-job工作原理（亮点）

XXL-JOB分布式任务调度服务由调用中心和执行器组成，调用中心负责按任务调度策略向执行器下发任务，执行器负责接收任务执行任务。如下图：

![img](E:\Typora\clip_image002-16770491573718.gif)

1. 首先部署并启动xxl-job调度中心。
2. 在微服务添加xxl-job依赖，在微服务中配置执行器名称、端口。
3. 启动微服务，执行器向调度中心上报自己。
4. 在微服务中写一个任务方法并用xxl-job的注解去标记执行任务的方法名称。
5. 在调度中心配置任务调度策略。
6. 在调度中心启动任务，根据任务调度策略，到达时间就开始下发任务给执行器。
7. 执行器收到任务就开始执行任务。

## XXL-Job都有什么优点？

> 美团

XXL-Job 是一款开源的分布式任务调度平台，具有以下优点：

1. 高可靠性：支持任务的分片执行，任务失败时自动重试，并且支持任务日志的查看，方便排查问题。
2. 分布式架构：支持多台服务器协同工作，任务可在多台服务器上分布式执行，提高了任务执行的效率。
3. Web界面友好：提供了友好的Web界面，方便任务管理人员进行任务的管理，如任务的新增、删除、执行、暂停等操作。
4. 容易集成：支持多种语言，提供了多种客户端API，如Java、Python、Golang等，易于集成到自己的应用程序中。
5. 高扩展性：支持任务的动态扩容和缩容，可根据业务需求自由调整任务的执行规模。
6. 周期性任务：支持定时任务和周期任务，可实现多种复杂的业务需求。
7. 操作简便：提供了RESTful API和命令行工具，方便开发人员进行任务的管理和操作。

总之，XXL-Job 是一款功能强大、易于使用的分布式任务调度平台，可以大大简化任务的管理和执行，提高任务执行的效率和可靠性。

## xxl-job宕机如何处理任务积压？

> 蚂蚁

当 xxl-job 服务宕机后，可能会导致任务无法被及时执行，从而导致任务积压。为了处理任务积压，可以采用以下几种方法：

1. 重启 xxl-job 服务：当 xxl-job 服务宕机后，可以尝试重启服务，以恢复任务的执行。在重启服务之前，需要确保 xxl-job 数据库中的数据没有丢失，并且需要检查任务执行状态，避免重复执行已经执行的任务。
2. 手动执行任务：当 xxl-job 服务宕机后，可以手动执行任务，以处理任务积压。在手动执行任务时，需要确保任务的执行环境和参数正确，并且需要检查任务执行状态，避免重复执行已经执行的任务。
3. 调整任务执行策略：当 xxl-job 服务宕机后，可以调整任务的执行策略，例如将任务的执行频率减少，或者将任务分批执行。这样可以避免任务积压过多，影响系统的稳定性。
4. 增加 xxl-job 服务节点：当 xxl-job 服务宕机后，可以增加 xxl-job 服务节点，以增加任务的处理能力。在增加服务节点时，需要考虑服务节点之间的任务调度策略，避免任务重复执行或者漏执行。

综上所述，为了处理 xxl-job 服务宕机导致的任务积压问题，可以采用重启服务、手动执行任务、调整任务执行策略和增加服务节点等方法，根据具体情况进行选择。同时，在处理任务积压时，需要注意任务执行的顺序和状态，避免出现任务重复执行或者漏执行的情况。

## Spring事务失效（问题）

在uploadFile方法上添加@Transactional，当调用uploadFile方法前会开启数据库事务，如果上传文件过程时间较长那么数据库的事务持续时间就会变长，这样数据库链接释放就慢，最终导致数据库链接不够用。

因此我将addMediaFilesToDb方法添加事务控制，uploadFile方法上的@Transactional注解去掉。然后我在addMediaFilesToDb方法中人为的写了一个异常来测试该方法是否能够被事务控制住进行事务回滚，发现出现了异常但数据库中依然存入了上传文件的信息，事务控制失败。

然后我去网上查了一下事务失败的原因进行排查，发现在uploadFile方法中去调用addMediaFilesToDb方法不是通过代理对象去调用

如何解决呢？通过代理对象去调用addMediaFilesToDb方法即可解决。在MediaFileService的实现类中注入MediaFileService的代理对象，将addMediaFilesToDb方法提成接口。

# 认证授权

## 认证授权模块怎么去做的？(难点)

### 认证

认证模块的话主要实现了账号密码模式和第三方认证登陆。账号密码模式比较简单，就是连接用户数据库拿到对应的用户名密码进行比对。

第三方认证这一块主要使用的微信扫码登陆。

### 授权

授权部分主要是基于RBAC实现的，RBAC主要分为两种，基于角色的访问控制（Role-Based Access Control），基于资源的访问控制（Resource-Based Access Control）。

角色的访问控制（Role-Based Access Control）是按角色进行授权，一个用户可以拥有若干角色，每一个角色又可以被分配若干权限。如果说访问某个资源或者使用某个功能的角色发生了变化，此时就需要去修改判断逻辑，系统的可扩展性是比较差的。因此我这边是主要采用基于资源的访问控制。当前用户必须拥有某个权限才可以使用当前功能或者访问当前资源。

本项目主要使用SpringSecurity来实现用户授权，在内容管理模块集成SpringSecurity，在需要授权的接口处使用@PreAuthorize("hasAuthority('权限标识符')")进行控制，本项目中普通用户无法访问内容管理部分，up主无法对自己上传的视频进行审核发布等。

整体流程：用户通过统一认证入口登陆，认证成功的话会颁发一个jwt令牌给用户，在生成jwt前会从数据库中查询用户的权限，查处的权限会放到jwt令牌中，用户携带这个jwt令牌通过网关去访问各个微服务，所有访问微服务的请求都要经过网关，这里还实现了网关鉴权。网关鉴权主要做两件事：针对不用认证的URL全部放行。除了白名单剩下的就是需要认证的请求，网关需要验证jwt的合法性，jwt合法则说明用户身份合法，否则说明身份不合法则拒绝继续访问。通过网关之后到达微服务中，需要控制访问权限的接口部分根据具体的需要使用@PreAuthorize("hasAuthority('权限标识符')")设置访问权限即可。

## OAuth2认证（亮点）

第三方认证（如微信扫码认证）是基于OAuth2协议实现的。

授权码模式：

1. 用户通过浏览器访问网站，打开扫码界面。
2. 用户扫码之后出现授权页面，询问用户是否授权当前网站访问自己在微信的用户信息，用户点击“确认登录”表示同意授权，微信认证服务器会颁发一个授权码给当前网站。
3. 当前网站获取到授权码后会携带授权码请求微信认证服务器申请令牌。
4. 微信认证服务器向当前网站响应令牌（jwt令牌）。
5. 当前网站携带令牌请求访问微信服务器获取用户的基本信息。
6. 资源服务器返回受保护资源即用户信息，当前网站接收到用户信息，登录成功。

密码模式：

1. 所有用户从统一登陆入口进行认证，使用的是OAuth2的密码模式进行认证，请求账号和密码到认证服务。
2. 认证服务对帐号和密码进行校验，校验成功颁发jwt令牌，响应给客户端。
3. 客户端将jwt令牌存到客户端cookie。然后携带jwt令牌通过网关去访问各微服务。
4. 网关对jwt令牌的合法性进行校验，校验成功继续访问，否则拒绝。
5. 请求到达微服务，微服务根据jwt中的权限信息校验用户是否拥有某个接口的权限，如果与则继续访问，没有则拒绝。

## 你还知道有什么类似的协议吗？

> 阿里

除了OAuth2之外，还有以下类似的协议：

1. OAuth1：OAuth1是OAuth2的前身，也是一种授权框架。与OAuth2相比，OAuth1使用签名密钥来保护用户凭据的安全性。但由于OAuth1具有较高的复杂性和安全风险，已逐渐被OAuth2替代。
2. OpenID Connect：OpenID Connect是一个基于OAuth2的身份验证协议，用于在Web应用程序中验证用户身份。它通过在OAuth2授权过程中添加身份验证信息来增强OAuth2的安全性和可靠性。
3. SAML：Security Assertion Markup Language（SAML）是一种XML-based标准，用于在不同的安全域之间传输身份验证和授权数据。SAML可用于Web单点登录，允许用户在一个身份验证域中进行身份验证，然后在另一个域中访问资源。
4. Kerberos：Kerberos是一个计算机网络身份验证协议，用于在客户端和服务器之间安全地传输身份验证信息。它通常用于企业网络中，允许用户通过一次身份验证即可访问多个资源。

这些协议都有其自己的特点和用途，可以根据具体的场景和需求选择合适的协议。

# 支付通知

## 详细说说订单模块？

> 美团基础平台

当用户点击“微信支付”或支付宝支付时执行流程如下：

![img](E:\Typora\clip_image002.gif)

1、请求视频订阅中心服务创建视频订阅记录

2、请求订单服务创建商品订单、生成支付二维码。

3、用户扫码请求订单支付服务，订单支付服务请求第三方支付平台生成支付订单。

4、前端唤起支付客户端，用户输入密码完成支付。

5、第三方支付平台支付完成发起支付通知。

6、订单支付服务接收支付通知结果并向视频订阅中心服务通知支付结果。

7、视频订阅中心服务收到支付结果，如果支付成功则更新视频订阅记录，并添加到我的播放列表。

## 如何解决同一个订单重复提交（幂等性问题）

订单重复提交是指当用户在提交订单的过程中，由于网络波动等原因，导致多次提交了相同的订单，从而产生重复订单的情况。为了解决这个问题，可以采用以下几种方法：

- 前端防止重复提交：在前端页面中，可以禁用提交按钮或者在用户提交订单后禁用提交按钮一段时间，避免用户多次提交相同的订单。

- 后端使用幂等性校验：在后端接口中，可以使用幂等性校验，当同一订单重复提交时，只执行一次提交操作。可以使用一些技术来实现幂等性，例如：

1. Token机制：

   服务端提供获取 Token 的接口，该 Token 可以是一个序列号，也可以是一个分布式 `ID` 或者 `UUID` 串。

   客户端调用接口获取 Token，这时候服务端会生成一个 Token 串。

   然后将该串存入 Redis 数据库中，以该 Token 作为 Redis 的键（注意设置过期时间）。

   将 Token 返回到客户端，客户端拿到后应存到表单隐藏域中。

   客户端在执行提交表单时，把 Token 存入到 `Headers` 中，执行业务请求带上该 `Headers`。

   服务端接收到请求后从 `Headers` 中拿到 Token，然后根据 Token 到 Redis 中查找该 `key` 是否存在。

   服务端根据 Redis 中是否存该 `key` 进行判断，如果存在就将该 `key` 删除，然后正常执行业务逻辑。如果不存在就抛异常，返回重复提交的错误信息。

   不过在高并发的场景下，这种方案还是存在一定的风险，如果token的获取、比较、删除这几个操作不是原子性的话，在高并发的场景下会导致获取到同样的token，同时判断成功，最终产生重复提交。因此在这里需要使用lua脚本来保证这三个操作的原子性。

2. 数据库唯一约束：

   客户端执行创建请求，调用服务端接口。

   服务端执行业务逻辑，生成一个分布式 `ID`，将该 ID 充当待插入数据的主键，然 后执数据插入操作，运行对应的 `SQL` 语句。

   服务端将该条数据插入数据库中，如果插入成功则表示没有重复调用接口。如果抛出主键重复异常，则表示数据库中已经存在该条记录，返回错误信息到客户端。

3. 数据库乐观锁：数据库乐观锁方案一般只能适用于执行**更新操作**的过程，我们可以提前在对应的数据表中多添加一个字段，充当当前数据的版本标识。这样每次对该数据库该表的这条数据执行更新时，都会将该版本标识作为一个条件，值为上次待更新数据中的版本标识的值。

4. 分布式锁：

总之，为了解决订单重复提交问题，需要在前端和后端两个方面来考虑，采用不同的技术手段来实现幂等性校验，从而避免产生重复订单的情况。

## 在微服务场景中，订单服务调用支付服务，如果支付服务挂掉了，没有调用成功，怎么处理？

> 蚂蚁

在微服务场景中，如果订单服务调用支付服务时发现支付服务挂掉了，没有调用成功，可以考虑以下几种处理方式：

1. 重试机制

可以在订单服务中实现重试机制，当支付服务调用失败时，自动进行多次重试，直到支付服务恢复正常。重试的时间间隔可以逐渐增加，避免给支付服务带来过大的压力。

2. 服务降级

可以在订单服务中实现服务降级机制，当支付服务挂掉时，自动切换到备用方案，如使用第三方支付服务或者提供代付等服务。降级后的服务虽然不如原来的服务功能强大，但是能够保证服务的可用性。

3. 异常处理

可以在订单服务中捕获支付服务调用异常，对异常进行处理。可以记录日志，提示用户稍后再试或者直接返回失败结果。如果支付服务的异常是由于临时的网络波动或者负载过大引起的，可以选择等待一段时间后再进行重试。

4. 通知处理

可以在订单服务中设置一个定时任务或者异步任务，定期检查支付服务的可用性，并及时通知相关负责人进行处理，避免支付服务长时间处于不可用状态。同时也可以通过监控系统实时监测服务的状态，及时发现服务挂掉的情况。

综上所述，在微服务场景中，如果支付服务挂掉了，没有调用成功，可以考虑采用重试机制、服务降级、异常处理和通知处理等方式进行处理，以保证服务的可用性和稳定性。

## 压力测试

样本数：200个线程，每个线程请求100次，共20000次

- 优化日志：内容管理⽇志级别改为error
- 优化网关：⽹关⽇志级别改为error，⾮debug启动，吞吐量达到1500左右
- 缓存优化：视频发布信息的特点的是查询较多，修改很少，这⾥考虑将视频发布信息进⾏缓存。吞吐量达到2700左右，增加了近⼀倍。

# redis

## 项目中redis主要用在哪？

缓存热点数据，这里主要是获取视频信息的接口，对于热门的视频点击量非常大，那么可以对这个接口进行一个缓存优化，将热门视频的信息存到redis中，以提高查询访问的效率，这个接口设置的缓存过期时间大概是7天。另外有关我的视频、我的订单这一类接口，短时间内也可能会重复查询，也会加一个缓存，过期时间大概在一个小时左右。

## 缓存优化

视频发布信息的特点的是查询较多，修改很少，这⾥考虑将视频发布信息进⾏缓存。大量的请求查询热门视频时并发量很大，不用每次都从数据库中查。

### 缓存穿透

如果有人恶意攻击，⼤量并发去访问⼀个数据库不存在的数据，由于缓存中没有该数据导致⼤量并发查询数据库，这个现象叫缓存穿透。

- 对请求增加校验机制。视频Id是⻓整型，如果发来的不是⻓整型则直接返回。
- 使用布隆过滤器。为了避免缓存穿透我们需要缓存预热将要查询的视频或商品信息的id提前存入布隆过滤器，添加数据时将信息的id也存入过滤器，当去查询一个数据时先在布隆过滤器中找一下如果没有到到就说明不存在，此时直接返回。
- **缓存空值**或特殊值。但是要注意：如果缓存了空值或特殊值要设置⼀个短暂的过期时间。

### 缓存雪崩

缓存雪崩是缓存中⼤量key拥有相同的过期时间，到达过期时间之后这些key会同时失效，当⾼并发到来时导致⼤量请求到数据库，瞬间耗尽数据库资源，导致数据库⽆法使⽤。

- 使⽤同步锁控制查询数据库的线程，只允许有⼀个线程去查询数据库，查询得到数据后存⼊缓存。
- 对同⼀类型信息的key**设置不同的过期时间**，这⾥可以在原有固定时间的基础上加上⼀个随机时间 使它们的过期时间都不相同。
- 使用多级缓存：可以将缓存分为多级，如本地缓存、分布式缓存等，不同级别的缓存过期时间不同，可以使缓存过期的时间错开，减少缓存雪崩的概率。

### 缓存击穿

缓存击穿是指⼤量并发访问同⼀个热点数据，当热点数据失效后同时去请求数据库，瞬间耗尽数据库资源，导致数据库⽆法使⽤。

- 使⽤同步锁控制查询数据库的代码，只允许有⼀个线程去查询数据库，查询得到数据库存⼊缓存。
- 热点数据不过期。可以由后台程序提前将热点数据加⼊缓存，缓存过期时间设置⻓⼀些或不过期，由后台程序做好缓存同步。
- 针对热点数据提前预热，将其存入缓存中并设置合理的过期时间比如秒杀场景下的数据在秒杀结束之前不过期。

### 分布式锁

上边的程序使⽤了同步锁解决了缓存击穿、缓存雪崩的问题，保证同⼀个key过期后只会查询⼀次数据库。如果将同步锁的程序分布式部署在多个虚拟机上则⽆法保证同⼀个key只会查询⼀次数据库。⼀个同步锁程序只能保证同⼀个虚拟机中多个线程只有⼀个线程去数据库，如果⾼并发通过⽹关负载均衡转发给各个虚拟机，此时就会存在多个线程去查询数据库情况，因为虚拟机中的锁只能保证该虚拟机⾃⼰的线程去同步执⾏，⽆法跨虚拟机保证同步执⾏。

本项目主要使用redisson来实现分布式锁。

1. 引入Redisson依赖

首先，需要在项目中引入Redisson依赖。可以在Maven或Gradle中添加以下依赖：

```xml
<dependency>
  <groupId>org.redisson</groupId>
  <artifactId>redisson</artifactId>
  <version>3.15.0</version>
</dependency>
```

2. 创建Redisson客户端

创建Redisson客户端来连接Redis服务器。可以使用以下代码来创建一个Redisson客户端：

```java
Config config = new Config();
config.useSingleServer().setAddress("redis://127.0.0.1:6379");

RedissonClient redisson = Redisson.create(config);
```

3. 获取分布式锁对象

使用Redisson客户端获取分布式锁对象。可以使用以下代码创建一个分布式锁对象：

```java
RLock lock = redisson.getLock("myLock");
```

其中，"myLock"是锁的名称。可以根据具体情况为锁指定一个唯一的名称。

4. 加锁

在需要加锁的代码块中，使用以下代码来获取锁：

```java
lock.lock();
```

如果锁已被其他进程获取，当前进程会阻塞等待锁的释放。

5. 解锁

在代码块执行完毕后，使用以下代码来释放锁：

```java
lock.unlock();
```

这样其他进程就可以获取到这个锁了。

完整的分布式锁的使用示例代码如下：

```java
Config config = new Config();
config.useSingleServer().setAddress("redis://127.0.0.1:6379");

RedissonClient redisson = Redisson.create(config);

RLock lock = redisson.getLock("myLock");

try {
    lock.lock();

    // TODO: 在这里执行需要加锁的代码块

} finally {
    lock.unlock();
}

redisson.shutdown();
```

## 项目为什么采用Redisson作为分布式锁，为什么不用Setnx的方式?

> 美团

Redisson 是一个基于 Redis 的分布式对象框架，它提供了一系列分布式锁的实现方式。相对于使用 Redis 的 Setnx 命令来实现分布式锁，Redisson 提供的分布式锁有以下优势：

1. 多样化的锁实现方式：Redisson 不仅提供了基于 Redis 的分布式锁实现方式，还提供了更多的锁实现方式，如基于 Redlock 算法的锁、读写锁、公平锁、联锁等。这些锁实现方式可以根据具体的业务场景选择最优的锁实现方式，提高锁的效率和可靠性。
2. 自动续期机制：Redisson 分布式锁在获取锁成功后会自动开启一个后台线程进行续期操作，保证锁不会因为业务处理时间过长而被自动释放，从而避免了因为业务处理时间过长导致的锁失效问题。
3. 支持异步加锁和解锁：Redisson 提供了异步加锁和解锁的方式，可以避免因为加锁和解锁操作阻塞导致的性能问题。
4. 更好的可扩展性：Redisson 的分布式锁可以方便地进行集群部署，支持多种分布式环境，如 Redis 集群、Sentinel 集群、AWS Elasticache 等，可以满足不同规模和复杂度的业务需求。

总之，Redisson 提供了更多的锁实现方式、自动续期机制、异步加锁解锁和更好的可扩展性，可以更好地满足不同业务场景下的需求。因此，很多项目会选择 Redisson 作为分布式锁的实现方式。

# nacos

## nacos注册中心实现原理

> 万得

服务注册时在服务端本地会通过轮询注册中心集群节点地址进行服务注册，在注册中心上，即Nacos Server上采用了Map保存实例信息，当然配置了持久化的服务会被保存到数据库中，在服务的调用方，为了保证本地服务实例列表的动态感知，Nacos与其他注册中心不同的是，采用了 Pull/Push同时运作的方式。

![面试官：用过 Nacos，说说 Nacos 服务注册的原理吧！_Nacos](https://s2.51cto.com/images/blog/202111/13204850_618fb43202e2062478.webp?x-oss-process=image/format,webp/resize,m_fixed,w_1184)

## nacos服务注册服务发现的原理

> 蚂蚁

Nacos（Naming and Config Service）是一个开源的服务发现和配置管理平台，其服务注册和发现的原理如下：

1. 服务注册：

当一个服务启动后，会向 Nacos 发送注册请求，包括服务名、IP 地址、端口号等信息。Nacos 接收到请求后，将服务信息保存在自己的数据库中，同时将服务信息同步到 Nacos 集群的其他节点上，以实现高可用性。服务实例会在一段时间内向注册中心发送心跳包来更新它们的状态，如果一个服务实例在规定的时间内没有发送心跳包，Nacos 就会认为该服务实例已经下线。

2. 服务发现：

当一个服务需要调用其他服务时，它会向 Nacos 发送服务发现请求，包括服务名和版本等信息。Nacos 接收到请求后，会从自己的数据库中查找与服务名匹配的服务实例，并返回给请求方。服务消费者可以根据自己的负载均衡策略选择其中一个实例进行调用。

## nacos集群如何保证一致性

> 蚂蚁

Nacos 通过 Raft 协议实现了一致性算法，从而保证了集群中各个节点的一致性。下面是一些保证 Nacos 集群一致性的方法：

1. Raft 协议：Nacos 使用 Raft 协议作为一致性算法，通过选举 Leader 节点来负责集群中的数据更新和同步，从而保证了数据一致性。Raft 协议将集群中的节点分为 Leader、Follower 和 Candidate 三种角色，只有 Leader 节点可以对数据进行修改，并将修改同步到所有 Follower 节点，从而保证了数据的一致性。
2. 数据同步：在 Nacos 集群中，Leader 节点负责将数据同步到所有 Follower 节点，以保证各个节点的数据一致性。当 Leader 节点更新数据时，会将数据的变更操作同步到其他 Follower 节点，从而确保集群中的所有节点的数据是一致的。
3. 心跳机制：在 Nacos 集群中，节点之间通过心跳机制来保持通信。每个节点都会定期发送心跳信号来检查其他节点的状态，并及时发现故障节点，从而保证集群的高可用性和数据一致性。
4. 配置检查：在 Nacos 集群中，会定期检查集群的配置信息，以确保配置信息的一致性。如果发现配置信息不一致，会尝试通过数据同步来解决问题。
5. 数据备份：Nacos 支持数据备份，可以将数据备份到多个节点中，以保证数据的可靠性和一致性。在节点故障或数据丢失时，可以通过备份数据来恢复数据，从而保证数据的一致性。

综上所述，Nacos 通过 Raft 协议、数据同步、心跳机制、配置检查和数据备份等多种方法来保证集群的一致性和高可用性。

## 如果在使用中Nacos服务挂掉了会有什么问题？

> 蚂蚁

Nacos是一款服务发现和配置管理工具，如果在使用中Nacos服务挂掉了，会导致以下问题：

1. 服务注册中心不可用：Nacos服务挂掉后，服务注册中心将不可用，新的服务实例将无法注册到注册中心，已注册的服务实例也无法被其他服务实例发现和调用。
2. 配置管理不可用：Nacos还提供了配置管理功能，如果Nacos服务挂掉了，那么配置信息将不可用，应用程序也无法获取新的配置信息，可能会导致应用程序出现异常或无法正常启动。
3. 高可用性问题：Nacos服务挂掉后，整个服务治理系统的高可用性将受到影响，因此在实际应用中，通常需要将Nacos配置为集群部署，以确保高可用性。

为了避免单点故障，可以通过将多个Nacos服务部署为集群的方式来提高可用性。另外，还可以采用服务降级和熔断等技术来应对Nacos服务挂掉的情况，以确保整个系统的稳定性。

## 有什么机制防止nacos挂掉？

为了防止Nacos挂掉，Nacos采用了Raft算法作为其分布式一致性协议，确保数据的可靠性和一致性。Raft算法是一种领导者选举算法，它将多个节点组织成一个集群，其中一个节点被选为领导者，负责处理客户端请求并维护集群状态。当领导者挂掉时，其他节点会发起新的领导者选举，确保集群中的节点都知道当前的领导者是谁。
